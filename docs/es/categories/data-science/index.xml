<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data-Science on </title>
    <link>https://www.danielsobrado.com/es/categories/data-science/</link>
    <description>Recent content in Data-Science on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>es-es</language>
    <lastBuildDate>Fri, 15 Mar 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://www.danielsobrado.com/es/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Likelihood encoding</title>
      <link>https://www.danielsobrado.com/es/blog/likelihood-encoding/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/likelihood-encoding/</guid>
      <description>Introduction Also known as mean encoding, impact encoding or target encoding, it is a technique</description>
    </item>
    
    <item>
      <title>Loss functions</title>
      <link>https://www.danielsobrado.com/es/blog/loss-rmse-mse-mae-mape/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/loss-rmse-mse-mae-mape/</guid>
      <description>Loss Functions The loss function calculates the difference between the output of your model and the &amp;ldquo;Ground Truth&amp;rdquo; or actual values.</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://www.danielsobrado.com/es/blog/logistic-regression/</link>
      <pubDate>Sun, 03 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/logistic-regression/</guid>
      <description>Introduction to Linear Regression A linear regression tries to estimate a linear relationship that best fits a given set of data.</description>
    </item>
    
    <item>
      <title>Model evaluation</title>
      <link>https://www.danielsobrado.com/es/blog/model-evaluation/</link>
      <pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/model-evaluation/</guid>
      <description>Introduction to Model Evaluation We need to test how well our model performs with data it has never seen before, to do this we can use multiple strategies depending on the amount of data we have, and the type of problem we are facing, we won´t approach on the same way, image recognition and structured time series problems.</description>
    </item>
    
    <item>
      <title>NLP: N-Grams and bag of words</title>
      <link>https://www.danielsobrado.com/es/blog/n-grams-and-bag-of-words/</link>
      <pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/n-grams-and-bag-of-words/</guid>
      <description>Introduction to N-Grams Introduction to Bag of Words </description>
    </item>
    
    <item>
      <title>Data Preparation: Missing Records</title>
      <link>https://www.danielsobrado.com/es/blog/data-preparation-missing-values/</link>
      <pubDate>Sat, 27 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/data-preparation-missing-values/</guid>
      <description>Missing Values are part of our data cleaning and pre-processing tasks, we are going to face features with missing values and we need to take a decision about what to do with those.</description>
    </item>
    
    <item>
      <title>Forward propagation in a Neural Network</title>
      <link>https://www.danielsobrado.com/es/blog/defining-the-neural-network/</link>
      <pubDate>Fri, 26 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/defining-the-neural-network/</guid>
      <description>Concepts When we count layers without taking into account the input payer.</description>
    </item>
    
    <item>
      <title>Data Preparation: Numeric</title>
      <link>https://www.danielsobrado.com/es/blog/data-preparation-numeric/</link>
      <pubDate>Fri, 26 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/data-preparation-numeric/</guid>
      <description>Introduction Data Preparation Mean Centering Standardization See: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py
Normalization </description>
    </item>
    
    <item>
      <title>Data Preparation: Categorical</title>
      <link>https://www.danielsobrado.com/es/blog/data-preparation-categoricals/</link>
      <pubDate>Thu, 25 Dec 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/data-preparation-categoricals/</guid>
      <description>Introduction Qualitative feature encoding Dummy enconding with Pandas DictVectorizer One-hot encoding Hashing trick </description>
    </item>
    
    <item>
      <title>Analysis of residuals</title>
      <link>https://www.danielsobrado.com/es/blog/residual-analysis/</link>
      <pubDate>Sat, 11 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/residual-analysis/</guid>
      <description>Introduction conda install statsmodels seaborn
Plotting residuals Regression assumptions Linearity and equal variance Normality</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://www.danielsobrado.com/es/blog/python-linear-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/python-linear-regression/</guid>
      <description>Introduction to Linear Regression A linear regression tries to estimate a linear relationship that best fits a given set of data.</description>
    </item>
    
    <item>
      <title>Clustering with Categorical Features</title>
      <link>https://www.danielsobrado.com/es/blog/clustering-categorical/</link>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/clustering-categorical/</guid>
      <description>Categorical variables Customer segmentation</description>
    </item>
    
    <item>
      <title>Kaggle: Mercari competition</title>
      <link>https://www.danielsobrado.com/es/blog/kaggle-mercari/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/kaggle-mercari/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fast Fourier Transform</title>
      <link>https://www.danielsobrado.com/es/blog/fast-fourier-transform/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/fast-fourier-transform/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RFM Scoring</title>
      <link>https://www.danielsobrado.com/es/blog/rfm-scoring/</link>
      <pubDate>Fri, 13 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/rfm-scoring/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/es/blog/customer-segmentation/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/customer-segmentation/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/es/blog/rfm-clustering-kmeans/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/rfm-clustering-kmeans/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/es/blog/rfm-clustering-number-clusters/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/rfm-clustering-number-clusters/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.</description>
    </item>
    
    <item>
      <title>Scipy: Introduction</title>
      <link>https://www.danielsobrado.com/es/blog/scipy-introduction/</link>
      <pubDate>Mon, 28 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/scipy-introduction/</guid>
      <description>Introduction </description>
    </item>
    
    <item>
      <title>Numpy: ndarrays</title>
      <link>https://www.danielsobrado.com/es/blog/numpy-ndarrays/</link>
      <pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/numpy-ndarrays/</guid>
      <description>Numpy lets us create arrays in multiple ways, most of the time in consonancy with core Python and other libraries like Pandas.</description>
    </item>
    
    <item>
      <title>Numpy: Introduction</title>
      <link>https://www.danielsobrado.com/es/blog/numpy-introduction/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/numpy-introduction/</guid>
      <description>Introduction Numpy is the core package for scientific computing, it has capabilities for fast processing of n-dimensional arrays and in general linear algebra.</description>
    </item>
    
    <item>
      <title>Naive Bayes</title>
      <link>https://www.danielsobrado.com/es/blog/naive-bayes/</link>
      <pubDate>Mon, 07 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/naive-bayes/</guid>
      <description>Introduction In Bayesian statistics there are two important concepts, we use probabilities to measure the uncertainty about the parameters used by the probability distributions, and we use the Bayes´ theorem to update those probabilities.</description>
    </item>
    
    <item>
      <title>Introduction to Data Science: Concepts</title>
      <link>https://www.danielsobrado.com/es/blog/datascience-concepts/</link>
      <pubDate>Fri, 03 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/datascience-concepts/</guid>
      <description>So many new concepts for the beginner data scientist, let´s start one by one:</description>
    </item>
    
    <item>
      <title>Numpy: Doing some maths</title>
      <link>https://www.danielsobrado.com/es/blog/numpy-maths/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/es/blog/numpy-maths/</guid>
      <description>Linear Algebra Matrix object This object is always two dimensional, and it doesn´t use the default broadcasting from ndarray.</description>
    </item>
    
  </channel>
</rss>
