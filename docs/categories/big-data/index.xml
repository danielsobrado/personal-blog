<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Big Data on </title>
    <link>https://www.danielsobrado.com/categories/big-data/</link>
    <description>Recent content in Big Data on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 10 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.danielsobrado.com/categories/big-data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Apache Spark: Properties precedence</title>
      <link>https://www.danielsobrado.com/post/apache-spark-properties-precedence/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/apache-spark-properties-precedence/</guid>
      <description>Proper Properties When starting with Spark jobs, one of the most common tasks is to understand how to finetune properties.
It is critical to define the right properties for your job, to avoid it to fail, or to take too long, at the same time you don&amp;rsquo;t want to be too greedy with the resources of your cluster, some might complain!
The problem When your codebase grows and you need some tools and you write some decent amount of code, you cannot just rely on an editor to edit the code and launch the job from the command line.</description>
    </item>
    
    <item>
      <title>Apache Spark: Introduction to project Tungsten</title>
      <link>https://www.danielsobrado.com/post/apache-spark-introduction-to-project-tungsten/</link>
      <pubDate>Fri, 28 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/apache-spark-introduction-to-project-tungsten/</guid>
      <description>Introduction Project Tungsten is available from Spark 1.4, Spark 2.x comes with the second generation of the Tungsten engine.
Tungsten is a compiler that applies to queries and generates optimized bytecode at runtime.
 Tungsten compiles your queries/stages into single bytecode JVM function that improve CPU efficiency and gain performance.
 This is one of those things that you could live without knowing about it and still do fine in Spark programming, but is extremely interesting and can be useful for advanced optimizations and to understand the insides of Spark.</description>
    </item>
    
    <item>
      <title>The machine data ecosystem</title>
      <link>https://www.danielsobrado.com/post/the-machine-data-ecosystem/</link>
      <pubDate>Sat, 28 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/the-machine-data-ecosystem/</guid>
      <description>Machine Data Platforms There are two known platforms for machine data, Splunk and Elastic Stack, let&amp;rsquo;s do some research&amp;hellip;
The cost of the platforms Splunk is great but the price tag is not that great, Elastic Stack is Open Source but some of the Enterprise features and Advanced Analytics capabilities are licensed on X-Pack under a paywall, can we get around some of these capabilities, like security using other Open Source solutions?</description>
    </item>
    
    <item>
      <title>Introduction to Machine Data</title>
      <link>https://www.danielsobrado.com/post/introduction-to-machine-data/</link>
      <pubDate>Sat, 18 May 2013 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/introduction-to-machine-data/</guid>
      <description>What is Machine Data With the rise of cheap storage and processing, we are in a better position to extract and process any type of data that can help with insights.
Any type of data produced by programs and processes is useful for us, we can use logs, network packets, any type of metrics and performance clues.
This means a large amount of unstructured data that is ready for our consumption and use.</description>
    </item>
    
  </channel>
</rss>