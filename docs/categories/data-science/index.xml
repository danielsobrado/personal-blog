<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data-Science on </title>
    <link>https://www.danielsobrado.com/categories/data-science/</link>
    <description>Recent content in Data-Science on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 15 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://www.danielsobrado.com/categories/data-science/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Tensorflow vs Pytorch: Basics</title>
      <link>https://www.danielsobrado.com/post/tensorflow-vs-pytorch-basics/</link>
      <pubDate>Sun, 25 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/tensorflow-vs-pytorch-basics/</guid>
      <description>Introduction The best way to learn a framework is to learn two at the same time and compare how things are being achieved in different ways, understanding the advantages and disadvantages.
Tensorflow and Pytorch are frameworks for fast tensor manipulation that is what is required for deep learning and some other machine learning methods.
Both heavily oriented towards machine learning and especially deep learning are low-level libraries to operate on tensors (n-dimensional arrays).</description>
    </item>
    
    <item>
      <title>Likelihood encoding</title>
      <link>https://www.danielsobrado.com/post/likelihood-encoding/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/likelihood-encoding/</guid>
      <description>Introduction Also known as mean encoding, impact encoding or target encoding, it is a technique
Mean Absolute Error (MAE) Measures average/mean squared error of our predictions.
Gives less weight to the outliers, when you are sure that they are outliers prefer MAE to MSE.
Mean Absolute Percentage Error (MAPE) &amp;hellip;
MAPE is
Mean Squared Error (MSE) Incorporates both the variance and the bias of the predictor.
When you have unexpected values that you should take into account use MSE instead of MAE.</description>
    </item>
    
    <item>
      <title>Loss functions: MAE, MAPE, MSE, RMSE and RMSLE</title>
      <link>https://www.danielsobrado.com/post/loss-functions-mae-mape-mse-rmse-and-rmsle/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/loss-functions-mae-mape-mse-rmse-and-rmsle/</guid>
      <description>Loss Functions The loss function calculates the difference between the output of your model and the &amp;ldquo;Ground Truth&amp;rdquo; or actual values.
All this functiones measure the ratio between actual/reference and predicted, the differences are in how the outliers impact the final outcome.
Each metric has its own strenghts and weakness and its fit for a different use case, we need to understand how these metrics impact our results, and how to interpret them, if they give us a relative or absulute value, the unit being used by the metric and how to use multiple metrics to understand where the loss/error is coming from.</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://www.danielsobrado.com/post/logistic-regression/</link>
      <pubDate>Sun, 03 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/logistic-regression/</guid>
      <description>Introduction to Linear Regression  A linear regression tries to estimate a linear relationship that best fits a given set of data.
 We need to understand that Linear Regression won´t help us with non linear relationships.
When we do a regression we are trying to understand the strength and direction of the relationship between two or more variables.
This is different from correlation analysis, because the model allows us to infer on new inputs.</description>
    </item>
    
    <item>
      <title>Analysis of residuals</title>
      <link>https://www.danielsobrado.com/post/analysis-of-residuals/</link>
      <pubDate>Sat, 11 Jan 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/analysis-of-residuals/</guid>
      <description>Introduction conda install statsmodels seaborn
Plotting residuals Regression assumptions Linearity and equal variance Normality
Interpreting residuals Common issues Heteroscedasticity Identify heteroscedasticity Breusch-Pagan Lagrange Multiplier test Using StatsModels we have statsmodels.stats.diagnostic.het_breuschpagan
Non-linearity Outliers Long Y-axis datapoints X-axis unbalanced </description>
    </item>
    
    <item>
      <title>Tensorflow vs Pytorch: Linear Regression</title>
      <link>https://www.danielsobrado.com/post/tensorflow-vs-pytorch-linear-regression/</link>
      <pubDate>Tue, 25 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/tensorflow-vs-pytorch-linear-regression/</guid>
      <description>Introduction to Linear Regression The best way to learn a framework is to learn two at the same time and compare how things are being achieved in different ways, understanding the advantages and disadvantages.
Tensorflow and Pytorch are frameworks for fast tensor manipulation that is what is required for deep learning and some other machine learning methods.
Both heavily oriented towards machine learning and especially deep learning are low-level libraries to operate on tensors (n-dimensional arrays).</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://www.danielsobrado.com/post/linear-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/linear-regression/</guid>
      <description>Introduction to Linear Regression  A linear regression tries to estimate a linear relationship that best fits a given set of data.
 We need to understand that Linear Regression won´t help us with non linear relationships.
When we do a regression we are trying to understand the strength and direction of the relationship between two or more variables.
This is different from correlation analysis, because the model allows us to infer on new inputs.</description>
    </item>
    
    <item>
      <title>Clustering with Categorical Features</title>
      <link>https://www.danielsobrado.com/post/clustering-with-categorical-features/</link>
      <pubDate>Fri, 15 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/clustering-with-categorical-features/</guid>
      <description>Categorical variables Customer segmentation</description>
    </item>
    
    <item>
      <title>Variational Autoencoders</title>
      <link>https://www.danielsobrado.com/post/variational-autoencoders/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/variational-autoencoders/</guid>
      <description>Autoencoders An autoencoder takes data with a large amount of parameters and tries to compress it into a smaller representation.
  Encoder:
  Bottleneck
  Decoder:
  Variational Autoencoders Variational Autoencoders is a technique to compress data</description>
    </item>
    
    <item>
      <title>RFM Scoring</title>
      <link>https://www.danielsobrado.com/post/rfm-scoring/</link>
      <pubDate>Fri, 13 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/rfm-scoring/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.
It customer cluster needs to be treated in a different way from multiple angles:
  Channels: Is a tech savvy customer? Or it is easier to call him? Is he suing tech but still going to the branch and we should advise him on more efficient ways to do his transactions?</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/post/customer-segmentation/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/customer-segmentation/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.
It customer cluster needs to be treated in a different way from multiple angles:
  Channels: Is a tech savvy customer? Or it is easier to call him? Is he suing tech but still going to the branch and we should advise him on more efficient ways to do his transactions?</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/post/customer-segmentation/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/customer-segmentation/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.
It customer cluster needs to be treated in a different way from multiple angles:
  Channels: Is a tech savvy customer? Or it is easier to call him? Is he suing tech but still going to the branch and we should advise him on more efficient ways to do his transactions?</description>
    </item>
    
    <item>
      <title>Customer Segmentation</title>
      <link>https://www.danielsobrado.com/post/customer-segmentation/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/customer-segmentation/</guid>
      <description>Why it matters? Customer segmentation nowadays is a basic tool of any bank, you want to classify your customers naturally and understand how cluster shift and evolve in time.
It customer cluster needs to be treated in a different way from multiple angles:
  Channels: Is a tech savvy customer? Or it is easier to call him? Is he suing tech but still going to the branch and we should advise him on more efficient ways to do his transactions?</description>
    </item>
    
    <item>
      <title>Scipy: Introduction</title>
      <link>https://www.danielsobrado.com/post/scipy-introduction/</link>
      <pubDate>Mon, 28 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/scipy-introduction/</guid>
      <description>Introduction </description>
    </item>
    
    <item>
      <title>Numpy: ndarrays</title>
      <link>https://www.danielsobrado.com/post/numpy-ndarrays/</link>
      <pubDate>Mon, 29 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/numpy-ndarrays/</guid>
      <description>Numpy lets us create arrays in multiple ways, most of the time in consonancy with core Python and other libraries like Pandas.
Creating ndarrays We can get Numpy vector and a matrix rapidly from a Python list:
We can quickly create matrices of ones and zeros:
Or any other value:
We can create ndarrays initialized with values:
Or generate ndarrays of random values:
We can observe some attributes from an ndarray, with the following operations, for an array defined as np.</description>
    </item>
    
    <item>
      <title>Numpy: Introduction</title>
      <link>https://www.danielsobrado.com/post/numpy-introduction/</link>
      <pubDate>Sun, 28 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/numpy-introduction/</guid>
      <description>Introduction Numpy is the core package for scientific computing, it has capabilities for fast processing of n-dimensional arrays and in general linear algebra.
There are multiple other well known packages in data science that rely on Numpy like Pandas and Scipy.
Installing Numpy For the examples we´ll just use pip to install Numpy, ideally it will be inside a container like Anaconda:
$ pip install numpyNumpy Arrays ndarray is the earth of NumPy, it&amp;rsquo;s the main data storage object of the framework.</description>
    </item>
    
    <item>
      <title>Naive Bayes</title>
      <link>https://www.danielsobrado.com/post/naive-bayes/</link>
      <pubDate>Mon, 07 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/naive-bayes/</guid>
      <description>Introduction In Bayesian statistics there are two important concepts, we use probabilities to measure the uncertainty about the parameters used by the probability distributions, and we use the Bayes´ theorem to update those probabilities.
Naive Bayes Types of Naive Bayes Algorithms Gaussian Naive Bayes We assume that each class has continuous Normal/Gaussian distributed values.
$$ P \left( x _ { i } | y \right) = \frac { 1 } { \sqrt { 2 \pi \sigma _ { y } ^ { 2 } } } \exp \left( - \frac { \left( x _ { i } - \mu _ { y } \right) ^ { 2 } } { 2 \sigma _ { y } ^ { 2 } } \right) $$</description>
    </item>
    
    <item>
      <title>Worldbank datasets: Jobs and economic indicators</title>
      <link>https://www.danielsobrado.com/post/worldbank-datasets-jobs-and-economic-indicators/</link>
      <pubDate>Fri, 28 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/worldbank-datasets-jobs-and-economic-indicators/</guid>
      <description>Introduction </description>
    </item>
    
    <item>
      <title>Numpy: Doing some maths</title>
      <link>https://www.danielsobrado.com/post/numpy-doing-some-maths/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.danielsobrado.com/post/numpy-doing-some-maths/</guid>
      <description>Linear Algebra Matrix object This object is always two dimensional, and it doesn´t use the default broadcasting from ndarray.
We can create an identity matrix using np.eye:
Statistics Reading and writing </description>
    </item>
    
  </channel>
</rss>