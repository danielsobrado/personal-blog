---
description: "In Information Theory receiving a bit reduces our uncertainty by half, or by a factor of 2. Our uncertainty reduction is the inverse of the probability of the event occurring."
author: "Daniel Sobrado"
date: 2014-06-21
linktitle: Cross-Entropy and KL-Divergence
nomenu:
  main:
    parent: tutorials
prev: /tutorials/mathjax
next: /prior-posterior-probabilities
title: Cross-Entropy and KL-Divergence
noweight: 10
image: https://i.imgur.com/EG7uO7w.png
tags : [
    "cross-entropy",
    "kl-divergence"
]
categories : [
    "Maths"
]
---

# Cross-Entropy



# Kullback Leibler Divergence




